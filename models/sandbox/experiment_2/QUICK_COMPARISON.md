# Quick Comparison: Before vs After

## Data Ingestion Changes

| Aspect | Before (Original Exp 2) | After (Updated with Exp 1 Style) |
|--------|------------------------|-----------------------------------|
| **Video Format** | Pre-extracted PNG frames in directories | Direct MP4 video files |
| **Loading Method** | `PIL.Image.open()` on PNG files | `cv2.VideoCapture()` on MP4 files |
| **Frame Extraction** | Pre-processing step required | On-the-fly during training |
| **Memory Usage** | High (all frames stored) | Lower (frames extracted as needed) |
| **Flexibility** | Limited to pre-extracted frames | Can adjust sampling on-the-fly |
| **Preprocessing** | Required separate script | None required |

## Model Changes

| Feature | Before | After |
|---------|--------|-------|
| **Attention Mechanism** | ‚ùå Not present | ‚úÖ Added (3D Conv + Sigmoid) |
| **Attention Weights** | ‚ùå N/A | ‚úÖ Per-frame weights [0,1] |
| **Gradient Clipping** | ‚ùå Not implemented | ‚úÖ Max norm = 1.0 |
| **Return Values** | Logits only | Logits + Attention weights |

## Training Changes

| Feature | Before | After |
|---------|--------|-------|
| **Optimizer** | Adam | AdamW (with weight decay) |
| **Learning Rate** | Fixed | Cosine Annealing Scheduler |
| **Gradient Clipping** | ‚ùå None | ‚úÖ Clip norm = 1.0 |
| **Accuracy Tracking** | ‚ùå Loss only | ‚úÖ Loss + Accuracy |
| **Checkpoint Saving** | Model weights only | Full training state |

## Inference/Output Changes

| Feature | Before | After |
|---------|--------|-------|
| **Outputs** | Video paths + confidence | Paths + confidence + attention |
| **Attention Data** | ‚ùå Not saved | ‚úÖ Saved for Stage 2 |
| **Top Frames** | ‚ùå N/A | ‚úÖ Top-5 attention indices |
| **Visualization** | ‚ùå None | ‚úÖ Attention plots |
| **Stage 2 Ready** | ‚ùå No | ‚úÖ Yes |

## Code Quality Changes

| Aspect | Before | After |
|--------|--------|-------|
| **Documentation** | Minimal | Detailed docstrings |
| **Error Handling** | Basic | Try-catch with fallbacks |
| **Comments** | Sparse | Comprehensive |
| **Code Structure** | Functional | Modular with helper functions |

## Performance Impact

### Expected Improvements:
- ‚úÖ **Faster Data Loading**: OpenCV is more efficient than PIL for video
- ‚úÖ **Lower Memory Footprint**: No need to store all extracted frames
- ‚úÖ **Better Model Interpretability**: Attention weights show what model focuses on
- ‚úÖ **Stable Training**: Gradient clipping prevents exploding gradients
- ‚úÖ **Stage 2 Ready**: Automatically prepares data for next stage

### Potential Considerations:
- ‚ö†Ô∏è **Training Time**: Attention mechanism adds ~10-15% overhead
- ‚ö†Ô∏è **Disk I/O**: More frequent video file access (offset by OpenCV efficiency)

## File Path Changes

```diff
# Dataset paths
- train_dir = r"C:\Users\rayaa\Downloads\ucf_crime\Train"
+ train_dir = r"C:\Users\rayaa\Downloads\ucf_crime_v2\Train"

# Checkpoint paths
- r"C:\Users\rayaa\Downloads\ucf_crime\crime_exist_checkpoints\binary_stage1.pt"
+ r"C:\Users\rayaa\Downloads\ucf_crime_v2\checkpoints\binary_stage1_with_attention.pt"
```

## Required Directory Structure

### Before:
```
Train/
  NormalVideos/
    video001/
      frame_0001.png
      frame_0002.png
      ...
```

### After:
```
Train/
  NormalVideos/
    video001.mp4
    video002.mp4
    ...
```

## Summary

üéØ **Main Achievement**: Experiment 2 now uses Experiment 1's superior data ingestion process while maintaining its own model architecture and training objectives.

üîë **Key Benefit**: The beefier computer's optimization from Experiment 1 is now available in Experiment 2, making it more practical to run Stage 1 and prepare for Stage 2.

‚ú® **Bonus**: Added attention mechanism aligns with Stage 1 goals of identifying crime-relevant frames for Stage 2 training.

